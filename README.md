# Early-intent-detection-MindSpore-Huawei-

[![MindSpore](https://img.shields.io/badge/MindSpore-2.3.0-red)](https://www.mindspore.cn/)
[![Python](https://img.shields.io/badge/Python-3.10-blue)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)


Exploraci√≥n de herramienta MindSpore para un caso pr√°ctico de aplicaci√≥n electr√≥nica. 

## Introducci√≥n

Mientras realizaba la capacitaci√≥n del HCIA.AI de Huawei; me top√© con MindSpore; y la verdad se me hizo interesante la propuesta y la comunidad en torno a este framework ... as√≠ tom√© la iniciativa de aplicarlo a un campo de electr√≥nica para averiguar el impacto que tendr√≠a en un caso pr√°ctico; as√≠ entonces trato de crear un sistema de detecci√≥n temprana de intenciones de movimiento basado en se√±ales **EMG (electromiograf√≠a)** de un sensor basado en mediciones del fabricante **NinaPro** (https://ninapro.hevs.ch/). Eventualmente incorporo **MindSpore** con objeto de predecir movimientos espec√≠ficos con alta precisi√≥n, lo que tiene aplicaciones en pr√≥tesis inteligentes y rehabilitaci√≥n;  estar√≠a muy interesante averiguar a profundidad el alcance real de este tipo de tecnolog√≠as pr√°cticas. 

## Objetivos

- **Detecci√≥n temprana**: Predecir intenciones de movimiento antes de su ejecuci√≥n completa
- **Clasificaci√≥n precisa**: Identificar movimientos a partir de se√±ales EMG
- **Implementaci√≥n eficiente**: Utilizar MindSpore para optimizar el proceso

## Preprocesamiento de Datos

### Estructura del Dataset
El archivo `S10_E1_A1.mat` contiene:
- **EMG**: 149,919 muestras √ó 16 canales
- **Stimulus**: 149,919 etiquetas de movimiento
- **Frecuencia**: 2000 Hz de muestreo

### Proceso de Ventaneo
```python
fs = 2000  # Hz - frecuencia de muestreo
window_size = 400  # 200 ms (0.2 * 2000)
step_size = 100    # 50 ms (0.05 * 2000) - 75% de solapamiento
```
###  Arquitectura CNN + LSTM para Clasificaci√≥n de Se√±ales EMG

Las se√±ales electromiogr√°ficas presentan:
- **Componentes temporales**: Patrones que evolucionan en el tiempo
- **Caracter√≠sticas locales**: Picos y formas de onda espec√≠ficas
- **Dependencias a largo plazo**: Relaciones temporales extendidas

## Fundamentaci√≥n Matem√°tica

### 1. **CNN para Extracci√≥n de Caracter√≠sticas Locales**

**Ventajas para se√±ales EMG:**
- **Invarianza temporal**: Detecta patrones independientemente de su posici√≥n
- **Extracci√≥n jer√°rquica**: Capas profundas capturan features complejas
- **Reducci√≥n de par√°metros**: Sharing de pesos mediante kernels

**Por qu√© LSTM para EMG:**
- **Memoria a largo plazo**: Captura dependencias temporales extendidas
- **Gate mechanisms**: Controla flujo de informaci√≥n temporal
- **Mitiga vanishing gradient**: Preserva gradientes en secuencias largas

## Arquitectura Propuesta: EMGNetRobust

### Especificaciones T√©cnicas

```python
class EMGNetRobust(nn.Cell):
    def __init__(self, num_classes):
        super(EMGNetRobust, self).__init__()
        
        # 1. CNN para features locales
        self.conv_block = nn.SequentialCell([
            nn.Conv1d(in_channels=16, out_channels=64, kernel_size=5, 
                     stride=1, pad_mode='pad'),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2, stride=2),
            
            nn.Conv1d(64, 128, kernel_size=3, stride=1, pad_mode='pad'),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2, stride=2),
        ])
        
        # 2. LSTM para dependencias temporales
        self.lstm = nn.LSTM(input_size=128, hidden_size=64, 
                           num_layers=1, batch_first=True)
        
        # 3. Clasificador denso
        self.classifier = nn.SequentialCell([
            nn.Dense(64, 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Dense(128, num_classes)
        ])

```

# Evaluaci√≥n y Predicci√≥n del Modelo

## M√©todos de Evaluaci√≥n Implementados

### Evaluaci√≥n del Modelo en Conjunto de Prueba

```python
# Evaluaci√≥n completa del modelo
metrics = model.eval(test_dataset, dataset_sink_mode=False)
print("Resultados en test:", metrics)

```

Aqu√≠ tenemos los siguientes ar√°metros clave:

**test_dataset:** Dataset de prueba preprocesado

**dataset_sink_mode=False:** Desactiva el modo de optimizaci√≥n para evaluaci√≥n precisa

### Predicci√≥n de Intenciones en tiempo real

```python
# Predicci√≥n de intenci√≥n en segmento individual
sample = X_test[0:1]   # Tomar un segmento de prueba
pred = model.predict(ms.Tensor(sample, ms.float32))
print("Predicci√≥n:", pred.asnumpy().argmax(axis=1))
print("Etiqueta real:", y_test[0])
```
## M√©tricas de Evaluaci√≥n

### M√©tricas Implementadas

```python
from mindspore.nn import Accuracy, Precision, Recall, F1

# Definici√≥n de m√©tricas
metrics = {
    'accuracy': Accuracy(),
    'precision': Precision(average='weighted'),
    'recall': Recall(average='weighted'),
    'f1_score': F1(average='weighted')
}

# Evaluaci√≥n comprehensiva
eval_results = model.eval(test_dataset, dataset_sink_mode=False)
```

# Detecci√≥n Temprana de Intenciones con Diferentes Ventanas Temporales

## Estrategia de Ventaneo para Detecci√≥n Temprana

Comparar el rendimiento del modelo utilizando ventanas de diferente longitud temporal para determinar el punto √≥ptimo de detecci√≥n temprana de intenciones de movimiento.

### Ventana Est√°ndar (40 muestras)

```python
# 40 muestras = 20ms (asumiendo 2000Hz)
X40, y40 = make_dataset(emg, stimulus, win_size=40)
print("X40:", X40.shape, "y40:", y40.shape)
# Salida: X40: (n_ventanas, 40, 16) y40: (n_ventanas,)
```

### Ventana Temprana (20 muestras)
```python
# 20 muestras = 10ms (detecci√≥n m√°s temprana)
X20, y20 = make_dataset(emg, stimulus, win_size=20)
print("X20:", X20.shape, "y20:", y20.shape)
# Salida: X20: (n_ventanas, 20, 16) y20: (n_ventanas,)
```

# Resultados del Experimento: Detecci√≥n Temprana con Diferentes Ventanas

## Resultados Obtenidos

### Estad√≠sticas de los Datasets
| Par√°metro | Ventana 40 | Ventana 20 |
|-----------|------------|------------|
| **N√∫mero de ventanas** | 3,747 | 7,495 |
| **Muestras por ventana** | 40 | 20 |
| **Duraci√≥n temporal** | 20ms | 10ms |
| **Dimensionalidad** | (40, 16) | (20, 16) |

### Rendimiento de Clasificaci√≥n
| M√©trica | Ventana 40 | Ventana 20 | Diferencia |
|---------|------------|------------|------------|
| **Accuracy** | 52.93% | 53.30% | +0.37% |
| **Precisi√≥n** | - | - | - |
| **Recall** | - | - | - |

## An√°lisis de los Resultados

### **Hallazgo Principal: Equivalencia de Rendimiento**
```python
# Resultados casi id√©nticos a pesar de diferente longitud temporal
accuracy_40 = 0.5293333333333333  # 52.93%
accuracy_20 = 0.5330220146764509  # 53.30%
diferencia = 0.003688  # Solo 0.37% de diferencia

```

# An√°lisis de Curvas de Entrenamiento y Validaci√≥n

## Resultados de las Curvas de Aprendizaje

### Curva de P√©rdida (Loss) de Entrenamiento

![Curvas de entrenamiento](loss_train.png)

**Tendencia Observada:**
- **Ventana 40**: P√©rdida inicial m√°s alta pero convergencia estable
- **Ventana 20**: P√©rdida inicial m√°s baja pero mayor variabilidad

**Interpretaci√≥n:**

Las ventanas de 20 muestras muestran:
- Mayor ruido en el gradiente (variabilidad en la p√©rdida)
- Pero convergencia final similar a ventanas de 40 muestras
- Capacidad de aprendizaje comparable a pesar de menos contexto temporal

# An√°lisis de los resultados para la Matriz de Confusi√≥n

## Descripci√≥n General

Ahora revisamos la matriz de confusi√≥n generada por un modelo de clasificaci√≥n para un problema de 13 clases (etiquetas 0 a 12). 

![Matriz de Confusion para la ventana 40](matriz40.png) 

![Matriz de Confusion para la ventana 20](matriz20.png)

- **Filas (Eje Vertical):** Representan la **etiqueta real** (la clase verdadera a la que pertenece cada instancia).
- **Columnas (Eje Horizontal):** Representan la **etiqueta predicha** (la clase que el modelo propuso).
- **Valores en las Celdas:** Indican el n√∫mero de instancias donde una etiqueta real (fila) fue clasificada como una etiqueta predicha (columna).

**Lectura:** Para evaluar el desempe√±o en la Clase X, se debe observar la fila correspondiente.
- **Aciertos:** Los valores en la diagonal principal (`[i,i]`) representan las predicciones correctas.
- **Errores:** Los valores fuera de la diagonal representan confusiones entre clases.

---

## Interpretaci√≥n por Clase Destacada para Ventana 40

### Clase 0 - Alto Desempe√±o
**Fila:** 0 1439 4 10 0 3 1 3 1 0 0 1 0 6

**Aciertos (1439):** La gran mayor√≠a de las instancias de la Clase 0 son identificadas correctamente. Esta es la clase con mayor n√∫mero de aciertos, lo que indica que el modelo es muy robusto para esta categor√≠a.

**Principales Errores:**
¬† - 10 instancias fueron confundidas con la Clase 2.
¬† - 6 instancias fueron confundidas con la Clase 12.

**Conclusi√≥n:** El modelo es excepcionalmente efectivo reconociendo la Clase 0, con un n√∫mero muy bajo de errores de clasificaci√≥n.

### Clase 10 - Alto Desempe√±o
**Fila:** 10 162 0 1 0 1 0 0 0 0 2 52 5 18

**Aciertos (52):** Aunque el n√∫mero de aciertos es menor que en otras clases, representa un rendimiento aceptable considerando la distribuci√≥n de la clase.

**Principal Error:**
¬† - 162 instancias fueron confundidas con la Clase 0.

**Conclusi√≥n:** El modelo tiene una alta tasa de aciertos para la Clase 10. Sin embargo, su principal debilidad es la confusi√≥n con la Clase 0, lo que sugiere que estas dos clases pueden tener caracter√≠sticas superpuestas que el modelo no logra diferenciar adecuadamente.

### Clase 5 - Bajo Desempe√±o
**Fila:** 5 34 0 10 2 33 101 8 1 0 0 0 0 1

**Aciertos (101):** El n√∫mero de aciertos es bajo en comparaci√≥n con los errores.

**Principales Errores:**
¬† - 34 instancias confundidas con la Clase 0.
¬† - 33 instancias confundidas con la Clase 4.
¬† - 10 instancias confundidas con la Clase 2.

**Conclusi√≥n:** El modelo tiene serias dificultades para identificar la Clase 5. La confunde predominantemente con las clases 0 y 4. Esto es una de las mayores √°reas de oportunidad para la mejora del modelo.

### Clase 2 - Bajo Desempe√±o (Problema Cr√≠tico)
**Fila:** 2 68 2 109 1 0 0 0 0 0 0 0 0 0

**Aciertos (109):** A pesar de tener 109 aciertos, el modelo demuestra una vulnerabilidad significativa.

**Principales Errores:**
¬† - 68 instancias fueron confundidas con la Clase 0. Este es uno de los errores m√°s significativos de todo el modelo.
¬† - 2 instancias fueron confundidas con la Clase 1.
¬† - 1 instancia fue confundida con la Clase 3.

**Conclusi√≥n:** La identificaci√≥n de la Clase 2 es un punto d√©bil del modelo. Existe una confusi√≥n notable con la Clase 0, lo que indica que el modelo tiene dificultades para diferenciar estas dos categor√≠as.

## Interpretaci√≥n por Clase Destacada para Ventana 20

### Clase 3 - Alto Desempe√±o
**Fila:** `3 40 20 0 306 0 0 0 0 4 0 0 0 1`

- **Aciertos (306):** La gran mayor√≠a de las instancias de la Clase 3 son identificadas correctamente.
- **Principales Errores:**
  - 40 instancias fueron confundidas con la **Clase 0**.
  - 20 instancias fueron confundidas con la **Clase 1**.
- **Conclusi√≥n:** El modelo es muy efectivo reconociendo esta clase, aunque existe una tendencia menor a confundirla con las clases 0 y 1.

### Clase 8 - Alto Desempe√±o
**Fila:** `8 91 0 0 1 0 0 0 3 269 1 1 0 0`

- **Aciertos (269):** Excelente tasa de predicci√≥n correcta.
- **Principal Error:**
  - 91 instancias fueron confundidas con la **Clase 0**.
- **Conclusi√≥n:** El modelo es muy preciso para la Clase 8. La confusi√≥n principal con la Clase 0 sugiere que podr√≠an compartir algunas caracter√≠sticas visuales.

### Clase 0 - Bajo Desempe√±o
**Fila:** `0 71 98 0 32 1 6 0 7 9 4 4 0 63`

- **Aciertos (71):** Muy baja cantidad de predicciones correctas.
- **Principales Errores:**
  - 98 instancias confundidas con la **Clase 1**.
  - 63 instancias confundidas con la **Clase 12**.
  - 32 instancias confundidas con la **Clase 3**.
- **Conclusi√≥n:** El modelo tiene serias dificultades para identificar la Clase 0. La confunde predominantemente con las clases 1, 12 y 3. Esta es una de las mayores √°reas de oportunidad.

### Clase 10 - Bajo Desempe√±o (Problema Cr√≠tico)
**Fila:** `10 288 1 0 2 0 0 0 0 2 28 123 0 37`

- **Aciertos (123):** Bajo n√∫mero de aciertos en proporci√≥n a los errores.
- **Principales Errores:**
  - **288** instancias confundidas con la **Clase 0**. Este es el error m√°s significativo de todo el modelo.
  - 37 instancias confundidas con la **Clase 12**.
  - 28 instancias confundidas con la **Clase 9**.
- **Conclusi√≥n:** La identificaci√≥n de la Clase 10 es el punto m√°s d√©bil del modelo. Existe una confusi√≥n abrumadora con la Clase 0, lo que indica que el modelo no ha aprendido a distinguir entre estas dos categor√≠as.


# An√°lisis Comparativo de Modelos - Ventana 20 vs. Ventana 40

![Grafica ROC-AUC ventana 40](RocAuc40.png) 

![Grafica ROC-AUC ventana 20](RocAuc20.png)

El modelo de la **Ventana 20** demuestra un mejor desempe√±o global y mayor estabilidad que el de la Ventana 40. Si bien ambos son robustos, la Ventana 40 presenta una regresi√≥n significativa en la clasificaci√≥n de la **Clase 10**, confirmada por ambas m√©tricas. Se recomienda utilizar la Ventana 20 como base y focalizar los esfuerzos de mejora en las clases 0 y 10.

---

## üìä Tabla Comparativa de M√©tricas ROC-AUC

| Clase | AUC V20 | AUC V40 | Diferencia (‚àÜ) | Tendencia y Comentario |
| :---- | :-----: | :-----: | :------------: | :--------------------- |
| **0** | 0.85 | 0.87 | **+0.02** | Leve mejora, pero sigue siendo un punto d√©bil. |
| **1** | 0.95 | 0.94 | -0.01 | Excelente y estable. |
| **2** | 0.95 | 0.93 | -0.02 | Excelente y estable. |
| **3** | 0.97 | 0.97 | 0.00 | Excepcional y consistente (Confirmado por MC). |
| **4** | 0.93 | 0.94 | +0.01 | Excelente y estable. |
| **5** | 0.97 | 0.94 | **-0.03** | Ligera regresi√≥n, pero se mantiene excelente. |
| **6** | 0.93 | 0.90 | **-0.03** | Regresi√≥n notable. Revisar en pr√≥ximas iteraciones. |
| **7** | 0.95 | 0.97 | **+0.02** | Mejora a nivel excepcional. |
| **8** | 0.95 | 0.94 | -0.01 | Excelente y estable (Confirmado por MC). |
| **9** | 0.90 | 0.89 | -0.01 | Bueno y estable. |
| **10** | 0.88 | 0.80 | **-0.08** | **Regresi√≥n cr√≠tica. El principal problema.** |
| **11** | 0.91 | 0.89 | -0.02 | Bueno y estable. |
| **12** | 0.97 | 0.95 | -0.02 | Excepcional y estable. |
| **üìä Promedio** | **~0.93** | **~0.91** | **-0.02** | **La V20 tiene un poder de discriminaci√≥n global superior.** |

**Leyenda:** MC = Matriz de Confusi√≥n

---

## Hallazgos Interesantes (ROC-AUC + Matriz de Confusi√≥n)

1.  **Problema Cr√≠tico Confirmado: Clase 10**
    *   **ROC-AUC:** Es la clase con el AUC m√°s bajo en ambas ventanas, con una **ca√≠da severa (-0.08) en la V40**.
    *   **Matriz de Confusi√≥n:** La matriz de la V20 mostr√≥ que es la clase con mayor confusi√≥n, siendo predicha incorrectamente como Clase 0 en la gran mayor√≠a de los casos.
    *   **Conclusi√≥n:** El modelo consistentemente no logra aprender los features discriminativos de la Clase 10. Este es el foco principal.

2.  **Punto D√©bil Secundario: Clase 0**
    *   **ROC-AUC:** AUC bajo pero estable (~0.86). Tiene margen de mejora.
    *   **Matriz de Confusi√≥n:** La matriz mostr√≥ que, si bien el modelo puede distinguirla (AUC decente), **se equivoca de manera espec√≠fica y masiva** (principalmente con las clases 1, 10 y 12).
    *   **Conclusi√≥n:** Es necesario investigar las similitudes visuales entre la Clase 0 y las clases 1, 10 y 12.

3.  **Puntos Fuertes Confirmados: Clases 3 y 8**
    *   **ROC-AUC:** AUC excepcional y estable (0.97 y ~0.95).
    *   **Matriz de Confusi√≥n:** Ambas mostraron una diagonal fuerte con altos aciertos.
    *   **Conclusi√≥n:** El modelo identifica estas clases de manera excelente y consistente.

---

## Recomendaciones

### 1. Decisi√≥n Estrat√©gica del Modelo
*   **Utilizar la Ventana 20 como modelo base.** Su desempe√±o global es superior y m√°s estable. La regresi√≥n en la Clase 10 en la V40 es inaceptable.

### 2. Acciones Inmediatas para Mejora
*   **Investigar el Dataset de la Clase 10:**
    *   ¬øHay suficientes ejemplos?
    *   ¬øLa calidad de las im√°genes es buena y consistente?
    *   **An√°lisis Visual:** Comparar im√°genes de la Clase 10 con las de la Clase 0 para identificar similitudes que confunden al modelo (ej: fondo, color, iluminaci√≥n, √°ngulo).

*   **Acciones para la Clase 0:**
    *   Realizar el mismo **an√°lisis visual** comparativo con las Clases 1 y 12.
    *   Aplicar **Data Augmentation** espec√≠fico para hacerla m√°s distintiva.
    *   Evaluar el ajuste del **umbral de clasificaci√≥n** para esta clase, sacrificando algo de *recall* por m√°s *precisi√≥n*.

